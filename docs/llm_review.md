好的。系统复习 LLM 可以从以下几个方面入手：

---

## 1. **模型结构**

* 基础：Transformer（注意力、前馈、归一化）。
* 变体：MoE（专家混合）、多查询注意力、旋转位置编码、线性注意力。
* Scaling law：性能随参数量 × 数据量 × 计算量的扩展规律。

## 2. **训练范式**

* **预训练**：大规模语料，next-token prediction。
* **微调**：领域适配、指令微调 (SFT)。
* **对齐**：RLHF、DPO、GRPO 等。
* **蒸馏**：大模型压缩为小模型。

## 3. **推理与效率**

* **解码技巧**：beam search、nucleus sampling、temperature。
* **测试时扩展**：CoT、ToT、自一致性。
* **效率方法**：early exit、token skipping、speculative decoding。

## 4. **推理能力**

* 显式推理（CoT） vs 隐式潜在推理。
* 大推理模型（LRM）。
* 自适应推理强度、避免 overthinking。

## 5. **验证与可靠性**

* Verifier、PRM、自一致性、集成。
* 不确定性估计、概率校准。

## 6. **外部工具**

* RAG（检索增强）。
* 计算器、代码执行器、符号推理。
* 长期记忆、规划型 agent。

## 7. **评测**

* **基准**：MMLU、BIG-Bench、MATH、Codeforces、AIME、LiveCodeBench。
* **指标**：准确率、pass\@k、F1、BLEU、困惑度、校准误差。

## 8. **安全与对齐**

* 拒答 vs 服从的权衡。
* 鲁棒性：对抗提示、越狱攻击。
* 可认证鲁棒性、红队测试、可解释性。

## 9. **应用**

* 通用：对话、摘要、翻译、检索。
* 专业：代码生成、科学推理、法律/医疗 NLP。

---

要不要我给你整理一份 **一页式复习清单**，方便在面试/组会前快速过一遍？
