å¥½çš„ï¼Œä¸‹é¢ç³»ç»Ÿæ¢³ç† **3. Model-level Attacks**ã€‚

---

# 3. Model-level Attacks (Direct Exploitation of Parameters)

è¿™ç±»æ”»å‡»ä¸ä¾èµ–è¾“å…¥æŠ•æ¯’æˆ–è®­ç»ƒæ•°æ®ï¼Œè€Œæ˜¯ç›´æ¥é’ˆå¯¹æ¨¡å‹æœ¬èº«çš„**å‚æ•°ã€å†…éƒ¨æœºåˆ¶ã€éšç§ä¿¡æ¯**ã€‚

---

## 3.1 Model Extraction / Stealing

* **Goal**: æ”»å‡»è€…é€šè¿‡æŸ¥è¯¢æ¨¡å‹ APIï¼Œè®­ç»ƒå‡ºä¸€ä¸ªè¿‘ä¼¼çš„å¤åˆ¶æ¨¡å‹ã€‚
* **Mechanism**:

  * Query-based distillationï¼šå¤§é‡è¾“å…¥â€“è¾“å‡ºå¯¹æ”¶é›†ã€‚
  * ç”¨è’¸é¦æˆ–æ¨¡ä»¿å­¦ä¹ è®­ç»ƒæœ¬åœ°æ¨¡å‹ã€‚
* **Impact**: çŸ¥è¯†äº§æƒç›—çªƒã€ç»•è¿‡ä»˜è´¹ APIã€è½¬ç§»å®‰å…¨å¼±ç‚¹ã€‚
* **Metrics**: Fidelity (å¤åˆ¶æ¨¡å‹ä¸åŸæ¨¡å‹è¾“å‡ºä¸€è‡´æ€§)ã€åŠŸèƒ½è¦†ç›–åº¦ã€‚
* **Defense**:

  * API rate limiting / æ°´å° (watermarking) è¾“å‡ºã€‚
  * Query auditingï¼ˆæ£€æµ‹å¤§è§„æ¨¡å¯ç–‘è°ƒç”¨ï¼‰ã€‚
  * Output perturbationï¼ˆå¯¹æŠ—è’¸é¦çš„ç»†å™ªå£°ï¼‰ã€‚

---

## 3.2 Membership Inference Attacks (MIA)

* **Goal**: åˆ¤æ–­æŸä¸ªæ ·æœ¬æ˜¯å¦åœ¨æ¨¡å‹è®­ç»ƒé›†é‡Œã€‚
* **Mechanism**:

  * æ¯”è¾ƒæ¨¡å‹å¯¹è¾“å…¥çš„ç½®ä¿¡åº¦ / è¿‡æ‹Ÿåˆç‰¹å¾ã€‚
  * Shadow model æ”»å‡»ï¼šè®­ç»ƒå¤šä¸ª shadow model æ¥ä¼°è®¡å·®å¼‚ã€‚
* **Impact**: è®­ç»ƒæ•°æ®éšç§æ³„éœ²ï¼ˆå¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼‰ã€‚
* **Metrics**: Membership inference accuracy (é«˜äºéšæœºçŒœæµ‹)ã€‚
* **Defense**:

  * Differential privacy training (DP-SGD)ã€‚
  * Regularization å‡å°‘è¿‡æ‹Ÿåˆã€‚
  * Confidence masking / è¾“å‡ºé™åˆ¶ã€‚

---

## 3.3 Model Inversion

* **Goal**: ä»æ¨¡å‹é¢„æµ‹ä¸­åæ¨è®­ç»ƒæ ·æœ¬çš„ç‰¹å¾ã€‚
* **Mechanism**:

  * ç»™å®šæŸç±»æ ‡ç­¾ï¼Œè¿­ä»£ç”Ÿæˆè¾“å…¥ï¼Œä½¿æ¨¡å‹é¢„æµ‹è¯¥æ ‡ç­¾æ¦‚ç‡æœ€å¤§ã€‚
  * æœ€ç»ˆå¾—åˆ°è¿‘ä¼¼äºè®­ç»ƒæ ·æœ¬çš„â€œåæ¼”å›¾åƒ/æ–‡æœ¬â€ã€‚
* **Impact**: ä¸ªäººéšç§æ•°æ®æ³„éœ²ï¼ˆå¦‚äººè„¸ã€åŒ»ç–—è®°å½•ï¼‰ã€‚
* **Defense**:

  * Differential privacyã€‚
  * é™åˆ¶è¾“å‡ºç½®ä¿¡åº¦ä¸ä¸­é—´è¡¨ç¤ºã€‚
  * æ¨¡å‹è’¸é¦é™ä½ä¿¡æ¯æ³„éœ²ã€‚

---

## 3.4 Fine-tuning-based Backdoor Injection

* **Goal**: é€šè¿‡ç”¨æˆ·å¯è®¿é—®çš„å¾®è°ƒæ¥å£ï¼Œå¾€ç°æœ‰æ¨¡å‹å‚æ•°é‡Œæ³¨å…¥åé—¨ã€‚
* **Mechanism**:

  * åˆ©ç”¨å¼€æ”¾ fine-tuning API æäº¤æ¶æ„æ•°æ®ã€‚
  * åœ¨åŸºç¡€æ¨¡å‹ä¸­åŸ‹å…¥è§¦å‘å™¨æ¨¡å¼ã€‚
* **Impact**: æ¨¡å‹åœ¨æ­£å¸¸ä»»åŠ¡æ­£å¸¸ï¼Œä½†è§¦å‘æ¡ä»¶ä¸‹è¢«åŠ«æŒã€‚
* **Defense**: å¾®è°ƒæ•°æ®å®¡è®¡ã€æ²™ç®±åŒ–è®­ç»ƒç¯å¢ƒã€è¾“å‡ºæ£€æµ‹ã€‚

---

## 3.5 Side-channel & Gradient Leakage

* **Goal**: ä»è®­ç»ƒè¿‡ç¨‹æˆ–æ¨ç† API çš„å‰¯ä¿¡é“æ³„éœ²ä¿¡æ¯ã€‚
* **Mechanism**:

  * è®­ç»ƒæ¢¯åº¦ä¸Šä¼ ï¼ˆåˆ†å¸ƒå¼/è”é‚¦å­¦ä¹ åœºæ™¯ï¼‰ â†’ é‡å»ºåŸå§‹è¾“å…¥ã€‚
  * Timing / memory access æ¨¡å¼ã€‚
* **Impact**: åŸå§‹è®­ç»ƒæ•°æ®æ³„éœ²ã€‚
* **Defense**:

  * Secure aggregation in federated learningã€‚
  * Gradient clipping + DPã€‚
  * Homomorphic encryption / secure enclaveã€‚

---

# Metrics for Model-level Attacks

* Extraction fidelity (è¿‘ä¼¼ç¨‹åº¦)ã€‚
* Membership inference accuracyã€‚
* Inversion reconstruction quality (PSNR, BLEU)ã€‚
* Attack stealthinessã€‚

---

# Defensive Baselines

* **Differential privacy**ï¼šå…¨å±€çº¦æŸè®­ç»ƒæ—¶çš„éšç§æ³„æ¼ã€‚
* **Regularization**ï¼šå‡å°‘è¿‡æ‹Ÿåˆï¼Œé™ä½ MIA æˆåŠŸç‡ã€‚
* **Access control**ï¼šé™åˆ¶ fine-tuning / gradient æ¥å£ã€‚
* **Output sanitization**ï¼šé¿å…è¿‡é«˜ç½®ä¿¡åº¦ã€‚
* **Watermarking**ï¼šæ ‡è®°è¾“å‡ºä»¥è¿½è¸ªæ»¥ç”¨ã€‚

---

ğŸ“Œ æ€»ç»“ï¼š
Model-level Attacks æœ¬è´¨ä¸Šæ˜¯â€œä»æ¨¡å‹æœ¬èº«æ¦¨å¹²ç§˜å¯†â€æˆ–â€œåœ¨æ¨¡å‹å†…éƒ¨åŸ‹å…¥æ¼æ´â€ã€‚åŒ…æ‹¬ **å‚æ•°çªƒå–ã€è®­ç»ƒé›†æ³„éœ²ã€åæ¼”éšç§ã€åé—¨æ³¨å…¥ã€æ¢¯åº¦æ³„æ¼**ã€‚

---

è¦ä¸è¦æˆ‘ç»§ç»­æ¢³ç† **4. System-level Attacks (Pipeline & Deployment)**ï¼Ÿ
