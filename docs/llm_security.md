å¥½çš„ã€‚æˆ‘ç»™ä½ ä» **LLM Security** å¼€å§‹ï¼Œé€å±‚æ¢³ç†å¸¸è§åˆ†ç±»ä½“ç³»ã€‚

---

# ğŸ”¹ LLM Security â€“ Big Picture

## 1. Input-level Attacks (Prompt / Data Manipulation)

è¿™äº›æ”»å‡»ç›´æ¥æ”¹è¾“å…¥ï¼Œåˆ©ç”¨ LLM çš„â€œä¾èµ–ä¸Šä¸‹æ–‡â€ç‰¹æ€§ã€‚

* **Prompt Injection**

  * *Instruction Override (Jailbreak)* â†’ è¦†ç›–åŸæŒ‡ä»¤ï¼Œç»•è¿‡é™åˆ¶ã€‚
  * *Context Injection (RAG poisoning)* â†’ åœ¨æ£€ç´¢æ–‡æ¡£é‡Œæ’å…¥æ¶æ„å†…å®¹ã€‚
  * *Data Exfiltration* â†’ å¼•å¯¼æ¨¡å‹æ³„éœ²ç³»ç»Ÿ prompt æˆ–æ•æ„Ÿä¿¡æ¯ã€‚
  * *Efficiency Abuse* â†’ å¼ºè¿«æ¨¡å‹è¿‡åº¦æ€è€ƒï¼ˆOverthink, Slowdownï¼‰ã€‚
* **Adversarial Examples (perturbations)**

  * åŠ æ‰°åŠ¨è¯ã€æ‹¼å†™å˜ä½“ã€å¯¹æŠ—å™ªå£°ï¼Œè¯±å¯¼åˆ†ç±»/ç”Ÿæˆé”™è¯¯ã€‚

---

## 2. Training-level Attacks (Model Poisoning)

è¿™äº›æ”»å‡»åœ¨è®­ç»ƒæˆ–å¾®è°ƒæ•°æ®ä¸­åŸ‹æ¯’ã€‚

* **Data Poisoning**

  * åœ¨è®­ç»ƒé›†ä¸­æ’å…¥å¸¦æ ‡ç­¾çš„æ¶æ„æ ·æœ¬ï¼Œå½±å“æ¨¡å‹è¡Œä¸ºã€‚
* **Backdoors**

  * åœ¨è®­ç»ƒä¸­åŸ‹ä¸‹è§¦å‘å™¨ï¼ˆtriggerï¼‰ï¼Œè¾“å…¥ç‰¹å®šå­—ç¬¦ä¸²æ—¶æ¨¡å‹è¾“å‡ºå¼‚å¸¸ã€‚

---

## 3. Model-level Attacks (Direct Exploitation of Parameters)

è¿™é‡Œæ˜¯ç›´æ¥å¯¹æ¨¡å‹æˆ–å…¶å†…éƒ¨æƒé‡ã€æœºåˆ¶åšæ–‡ç« ã€‚

* **Model Extraction / Stealing**

  * é€šè¿‡ API è°ƒç”¨çªƒå–å‚æ•°æˆ–è’¸é¦æˆè¿‘ä¼¼æ¨¡å‹ã€‚
* **Jailbreak via Gradient / Optimization**

  * åˆ©ç”¨å¯å¾®ç»“æ„ï¼ˆæˆ– RLHF ç¼ºé™·ï¼‰æ‰¾åˆ°ç³»ç»Ÿå¼±ç‚¹ã€‚
* **Membership Inference**

  * åˆ¤æ–­æŸä¸ªæ ·æœ¬æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®é‡Œ â†’ éšç§æ³„éœ²ã€‚

---

## 4. System-level Attacks (Pipeline & Deployment)

å…³æ³¨æ¨¡å‹ä½œä¸ºæœåŠ¡éƒ¨ç½²æ—¶çš„æ•´ä½“æ¼æ´ã€‚

* **RAG Pipeline Poisoning**

  * é’ˆå¯¹å‘é‡æ•°æ®åº“æˆ–æ£€ç´¢æœºåˆ¶æŠ•æ¯’ã€‚
* **Data Leakage via Logs/Cache**

  * çªƒå–æç¤ºå†å²ã€ç¼“å­˜ç»“æœã€‚
* **Abuse of Cost/Latency**

  * DoS-style attacksï¼ˆå¦‚ Overthink token æ¶ˆè€—ï¼‰ã€‚
* **API Misuse**

  * åˆ©ç”¨è°ƒç”¨é¢‘ç‡æˆ– token é™åˆ¶æ‹–å®æœåŠ¡ã€‚

---

## 5. Output-level Risks (Content & Behavior)

å…³æ³¨æ¨¡å‹ç”Ÿæˆå†…å®¹æœ¬èº«ã€‚

* **Hallucination** â†’ æ¨¡å‹ç¼–é€ é”™è¯¯ä¿¡æ¯ã€‚
* **Toxicity** â†’ è¾“å‡ºæœ‰å®³è¨€è®ºã€‚
* **Bias / Fairness Issues** â†’ å¼ºåŒ–åè§æˆ–æ­§è§†ã€‚
* **Misuse** â†’ æ”»å‡»è€…å¼•å¯¼ç”Ÿæˆæ¶æ„ä»£ç ã€è¯ˆéª—æ–‡æœ¬ã€çˆ†ç‚¸é…æ–¹ã€‚

---

# ğŸ“Œ æ€»ç»“çš„æ ‘çŠ¶è„‰ç»œ

```
LLM Security
â”œâ”€â”€ Input-level Attacks
â”‚   â”œâ”€â”€ Prompt Injection
â”‚   â”‚   â”œâ”€â”€ Instruction Override (Jailbreak)
â”‚   â”‚   â”œâ”€â”€ Context Injection (RAG poisoning)
â”‚   â”‚   â”œâ”€â”€ Data Exfiltration
â”‚   â”‚   â””â”€â”€ Efficiency Abuse (Overthink/Slowdown)
â”‚   â””â”€â”€ Adversarial Examples
â”œâ”€â”€ Training-level Attacks
â”‚   â”œâ”€â”€ Data Poisoning
â”‚   â””â”€â”€ Backdoors
â”œâ”€â”€ Model-level Attacks
â”‚   â”œâ”€â”€ Model Extraction
â”‚   â”œâ”€â”€ Jailbreak via Gradients
â”‚   â””â”€â”€ Membership Inference
â”œâ”€â”€ System-level Attacks
â”‚   â”œâ”€â”€ RAG Pipeline Poisoning
â”‚   â”œâ”€â”€ Data Leakage (Logs/Cache)
â”‚   â”œâ”€â”€ Cost/Latency Abuse
â”‚   â””â”€â”€ API Misuse
â””â”€â”€ Output-level Risks
    â”œâ”€â”€ Hallucination
    â”œâ”€â”€ Toxicity
    â”œâ”€â”€ Bias / Fairness
    â””â”€â”€ Misuse
```

---

è¦ä¸è¦æˆ‘æŠŠè¿™ä¸ª **å¤§å›¾æ™¯** ç”¨è‹±æ–‡ç‰ˆæ ‘çŠ¶å›¾ç”»å‡ºæ¥ï¼ˆåƒä½ åˆšæ‰è¦çš„ prompt injection å›¾é‚£æ ·ï¼‰ï¼Ÿ
