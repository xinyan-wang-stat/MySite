**Output-based: Dynamic Reasoning Paradigm** 属于综述中“输出端的效率方法”。它强调：**不要总是生成固定长度的完整推理链**，而是让模型在 **推理过程中动态决定“生成多少、生成什么形式”**，从而减少冗余 token，提升效率。

---

# 背景

* **传统 CoT**：每个问题都生成一整条长推理链，token 开销大，且不一定总能提升准确率。
* **目标**：在输出端实现 **自适应推理**——根据问题难度和当前置信度，决定推理链的 **长度**、**内容形式**（自然语言 or 压缩摘要）甚至 **结构**。

---

# 典型机制

1. **动态长度控制**

   * 模型在生成过程中监测不确定性（熵、PRM 得分等）。
   * 若已足够自信则 **提前终止**；若不确定则继续展开。
   * 例子：**TALE-EP** 用 token-level 熵做 early stop；**Dynasor-CoT** 用 Certaindex 控制是否继续生成。

2. **压缩式推理**

   * 生成中途把长链压缩为更短的 **摘要 token**，继续在摘要上展开。
   * 例子：**LightThinker** 训练 LLM 学会何时/如何压缩成 gist tokens；**InftyThink** 每步生成后立即摘要，只保留滚动摘要，避免上下文爆炸。

3. **自截断与筛选**

   * 并行采样时，用一致性或置信度指标提前筛掉无前途的样本。
   * 例子：**ST-BoN** 用 embedding 一致性提前截断低质量样本。

---

# 优势

* **节省 token**：对简单题可大幅缩短输出。
* **动态适应**：复杂题仍能展开更多推理。
* **通用性**：训练无关或轻量微调即可用。

---

# 与其它类别对比

* **Input-based**：通过 prompt 设计减少不必要的思维（如少量提示、指令约束）。
* **Model-based**：在模型内部改结构（如 early exit、动态层）。
* **Output-based**（这里）则直接在 **生成结果层面**做动态调节，最贴近最终推理输出。

---

要不要我帮你做一张 **“Output-based Dynamic Reasoning 方法图谱”**，把 TALE-EP、LightThinker、InftyThink、ST-BoN 这些方法放进去，用箭头表示它们分别解决“长度控制 / 压缩 / 筛选”的不同子方向？
