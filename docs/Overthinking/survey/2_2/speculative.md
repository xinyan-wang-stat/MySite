结论：**Speculative Rejection (SR)** 是一种**推理期的高效 BoN 解码**。做法：先用较大的并行批量生成候选，**用奖励模型对早期片段打分并周期性淘汰低分样本**，释放显存继续扩展高分样本，从而在**不完整生成全部 N 条**的前提下达到与 BoN 相近或更高的效果，显著降算力开销。

# 机制

* **大批量起步**：以接近显存上限的并行样本数启动 BoN。
* **早期评估**：用**奖励模型/PRM**对**部分生成**进行质量估计。
* **周期性淘汰**：按评分丢弃劣质样本，腾出资源继续扩展剩余样本。
* **终止与选择**：到预算或停止条件后，从存活样本中用投票或奖励选最优答。

# 为什么更省

* 传统 BoN 会**完整生成 N 条**再评估，**SR 只对有希望的样本继续生成**，因此**减少无效计算与显存占用**。

# 与相近方法

* **ST‑BoN**：基于**潜在表示一致性**的早停与截断，不依赖外部奖励模型；SR 用奖励模型做打分。
* **RSD**：把“奖励引导”用于**推测解码**，用 PRM 接受小草稿模型的中间输出；SR 优化的是 BoN 采样流程本身。

# 最小实现（伪代码）

```
init batch = B_max_near_mem
S = sample_prefixes(batch, max_steps=t0)
while budget_not_exceeded:
    scores = reward_model.score(S)        # 评估部分生成
    S = keep_top_k(S, scores, k)          # 淘汰低分
    S = extend_each(S, Δt)                # 仅扩展存活样本
return select_best(S)                     # 投票/最高奖赏
```

依据：\*\*“大批量起步→周期性拒绝→持续生成”\*\*的 SR 流程。

# 实操要点

* **评估间隔 Δt**：过短噪声大，过长浪费算力。
* **留存比例 k/B**：保守留存能稳准确率，激进留存更省算。
* **奖励模型**：用 PRM/Reward Model 评估**过程质量**优于只看终答案。
* **停止条件**：到达 token/时间预算，或分数收敛。

# 适用场景与限制

* 适合**训练期零改**的部署优化，尤其是**数学/代码**这类多步推理。
* 依赖奖励模型质量；评分失真会**误砍**正确路径，可配置信心阈值与“回看”机制缓解。

一句话：**SR = 用奖励驱动的“边生成边淘汰”的 BoN**，把算力集中到最有前途的思路上，**以更少样本完成原本需要完整 N 条的搜索**。
