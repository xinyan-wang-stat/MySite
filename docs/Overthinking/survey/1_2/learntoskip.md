好的，我们来详细拆解 **Learn to Skip \[70]**，它是“可变长度 CoT 数据 + SFT”路线下的一个方法，专门教模型**学会自动跳过不必要的推理步骤**。

---

## 1. 背景问题

* 传统长链 CoT 往往写得很啰嗦，很多中间步骤对最后答案没什么帮助。
* 单纯靠 RL 长度惩罚或后处理压缩，模型本身并没真正“理解哪些步骤可以省略”。
* Learn to Skip 的目标：**让模型在推理时本能地学会省略冗余**，而不是事后靠压缩。

---

## 2. 方法核心

它采用了 **两阶段训练**：

### 阶段 1：构造跳步示范数据

* 对已有长链 CoT，人工或用规则方法标记哪些步骤是**关键步骤**，哪些是**可跳过的冗余**。
* 例如：在多步算术题中，若某些检查/重复步骤对最终答案无贡献，就标记为“可跳过”。
* 这样得到的数据会同时包含“全链”和“跳过版链”。

### 阶段 2：训练模型学会“跳步”

* 在 SFT 阶段，把“跳过版链”作为主要训练目标，让模型模仿更短的推理路径。
* 在 prompt 或训练标签里明确提示模型：“请只写必要步骤”。
* 最终，模型在生成时就会自然地产生更短的链路。

---

## 3. 技术细节

* **数据来源**：通常来自数学/逻辑数据集（如 GSM8K、MATH），先生成长链，再做跳步标注。
* **跳步机制**：

  * 可以通过启发式规则（如只保留能导致状态转移的关键步骤）。
  * 也可以用强模型/GPT-4 去压缩长链，生成带“跳过提示”的数据。
* **训练目标**：交叉熵 SFT，直接模仿短链。
* **评测**：关注两个指标：

  1. 准确率是否下降。
  2. 平均推理 token 数是否减少。

---

## 4. 效果

* **优势**：

  * 模型不仅能少写，还能**学会判断哪些步骤可省略**。
  * 推理链更简洁，成本更低。
  * 保持了一定的可解释性（不像 Distilling 2-1 直接丢掉推理）。
* **不足**：

  * 数据准备需要额外人工/规则/强模型干预。
  * 如果跳步标注不准，可能会误删关键逻辑 → 答案错误。

---

## 5. 与其他方法对比

* **TokenSkip**：在后处理阶段根据语义重要性删除 token → 更像“离线裁剪”。
* **Learn to Skip**：直接在训练时让模型学会“主动跳过” → 是一种“内化的节省习惯”。
* **C3oT**：由 GPT-4 压缩 → 外部教师压缩法。
* **Distilling 2-1**：只留答案 → 最快但无推理链。

---

## 6. 应用场景

* **算术/逻辑类数据集**：冗余推理特别多。
* **需要保留解释性**：不同于 Distilling 2-1，Learn to Skip 仍然生成精简 CoT。
* **小模型蒸馏**：帮助小模型快速学会“高效推理风格”。

---

✅ 一句话总结：
**Learn to Skip 通过两阶段训练（构造跳步示范 → SFT 学习），让模型真正学会在生成时主动省略冗余推理步骤，得到短而准的 CoT。**

---

要不要我帮你画一张 Learn to Skip 的两阶段训练流程图（长链 → 跳步标注 → 短链 → SFT）？