# Distilling 2-1 \[142]

---

## 1. 背景

* 大模型（如 GPT-4）在推理时会输出**长链 CoT**，虽然正确率高，但推理成本大。
* 如果我们只想要一个“**快而准**”的小模型，可以考虑：

  * 把强模型的 **长链推理**蒸馏给小模型，
  * 但训练时 **不保留中间推理步骤**，而是只保留 **输入 + 最终答案**。
* 这样，小模型学到的就是“直接出结果”而不是“复现冗长推理”。

---

## 2. 方法核心 —— “2-1” 的含义

* **2**：长链推理样本包含两部分 → **推理过程 (CoT)** + **最终答案**。
* **1**：蒸馏时，只保留 1 部分 → **最终答案**。

也就是说：

1. 用大模型生成 “问题 → 长链推理 → 最终答案” 数据。
2. 蒸馏时去掉推理链，只保留 “问题 → 答案” 作为训练样本。
3. 小模型学到的是“快速直答”，而不是“逐步思考”。

---

## 3. 训练方式

* **数据准备**：

  * 问题：数学题、逻辑题、常识问答等。
  * 输出：大模型完整 CoT，取最后的“答案”。
  * 删除 CoT，只留 (x, y\_ans)。

* **训练目标**：

  * 标准交叉熵 SFT，强制小模型直接输出答案。
  * 不再生成 `<think>` 或 CoT。

---

## 4. 效果与作用

* **优点**：

  * 大幅减少推理长度（没有 CoT，答案直接生成）。
  * 成本低，延迟小，适合**应用场景对速度敏感**但不要求可解释性。
  * 小模型能继承大模型的“正确答案分布”。

* **缺点**：

  * 小模型**失去显式推理能力**，面对难题容易崩溃。
  * 泛化到复杂任务时效果差，不如保留部分短链数据（比如 Self-Training、C3oT）。

---

## 5. 对比其他方法

* **C3oT**：保留精简版 CoT → 模型还能学到“简洁推理”。
* **TokenSkip**：跳过不重要的 token，但保留骨架推理。
* **Distilling 2-1**：直接丢掉推理链 → 模型变“快答机器”。

换句话说：

* C3oT/TokenSkip：教模型**少想**。
* Distilling 2-1：教模型**不想，直接答**。

---

## 6. 实际应用场景

* **轻量应用**：如客服问答、简单数学计算、事实型 QA，需要快速响应。
* **边缘设备**：资源受限的小模型（1B–7B），不适合生成长 CoT。
* **对解释性要求低的任务**：答案本身重要，过程不重要。

---

✅ 一句话总结：
**Distilling 2-1 = “用长链数据教小模型，但只蒸馏最后答案”。它让小模型速度快、成本低，但牺牲显式推理能力。**


