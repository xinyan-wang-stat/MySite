**答案**：Chain of Draft（CoD）是在“想步骤”的同时强制“只保留极简草稿”。每步只写几词要点，最后再给答案。这样保留逻辑骨架，压缩冗余 token，显著降成本，同时尽量不掉准确率。

### 核心概念

* 目标：以最少的中间文字完成可核查的推理。
* 规则：每个思考步最多 N 个词（论文示例用 5 词），末尾用分隔符后给出最终答案。
* 与 CoT 区别：CoT写全程；CoD只写“提纲式要点”。

### 标准提示词（论文给法）

* 英文版：
  “Think step by step, **but only keep a minimum draft for each step, with at most 5 words**. Return the answer at the end after `####`.”&#x20;
* 中文等价：
  “逐步思考，但**每步仅保留不超过5个词的草稿要点**。最后在 `####` 后给出答案。”

### 推理流程（单次）

1. 读题。
2. 逐步生成“要点式”草稿：每步 ≤ N 词。
3. `####` 后输出最终答案。
4. 校验：若答案缺证据或不自洽，放宽 N 或补 1–2 步。

### 推理流程（多样本解码可选）

* Best-of-N：并行采样多条“极简草稿”。按投票或 PRM 评分选优。可结合“长度过滤”或不一致早停，进一步省算力。

### 何时用

* 简单或中等难度题。
* 严格 token/时延预算。
* 作为蒸馏或SFT的“短链路数据”采集器。

### 经验参数

* 每步词数 N：3–7 常用；题难↑时适度↑。
* 步数软上限：4–8 步起步。
* 失败时的放宽顺序：步数→每步词数。

### 评估指标

* 准确率（Acc）。
* 思考 token（reasoning tokens）。
* 总 token、延迟、\$/\$成本。
* 压缩–准确率曲线，用于挑选 N 与步数。

### 与近邻方法对比

* **CCoT**：“保持简洁”但不硬性设上限；CoD有**每步词数硬约束**。
* **Token-Budget**：先估预算再约束总长度；CoD约束**每步粒度**，更可控，易解析。
* **Token Complexity**：研究任务所需最小信息量；可用来设定 CoD 的步数与每步词数下界。

### 训练与集成

* **SFT 数据构造**：用 CoD 提示批量生成“短CoT”轨迹，再用作监督微调，教会模型“少写也对”。
* **RL**：在准确奖励外加长度/超长惩罚，与 CoD 解码并用。
* **动态推理**：和 BoN 早停、长度过滤投票、置信度路由结合，进一步降算。

### 典型失败与修复

* 丢关键中间量 → 放宽每步词数或加“必须给出中间量X”。
* 答案段缺失或格式错 → 正则化输出模板（固定 `#### <final>`）。
* 难题准确率掉幅大 → 启用两段式：先 CoD，再对“草稿不自洽”样本回退到短CoT。

### 最小示例

**题**：\$37\times 25=?\$
**CoD草稿**：

1. 拆分：\$25=100/4\$
2. 先乘：\$37\times 100=3700\$
3. 再除：\$3700/4=925\$
   `#### 925`

### 实施要点

* 强提示+硬规则：限制每步词数与总步数，固定答案分隔符。
* 解析器：按行抽取草稿，`####` 后取最终答案。
* 回退策略：错或不自洽时自动放宽一次。

以上内容与 CoD 的定义、提示模板、位置关系与评测要点均来自该综述的“Prompt-guided Efficient Reasoning”部分与表格条目。
