**Input Prompts-based: Prompt-Guided Efficient Reasoning** 是综述里“输入端”效率类方法之一。它的思路很直接：**通过设计提示词（prompts），让模型在推理时自觉控制长度、减少冗余**，不需要改模型或额外训练。

---

# 背景

* **问题**：普通 *Chain-of-Thought (CoT)* 提示会让模型倾向于生成很长的解释，导致 token 成本高。
* **目标**：利用 **prompt 工程** 在输入阶段约束模型输出，从源头减少过长或无效的推理。

---

# 代表方法

1. **Chain of Draft (CoD)**

   * 提示模型“逐步思考，但每步只保留几个词的草稿”。
   * 每步最多 N 个词，最后在 `####` 后输出答案。
   * 效果：保留逻辑骨架，显著压缩 token 数，同时不大幅损失准确率。

2. **CCoT（Concise CoT）**

   * 提示模型“保持简洁推理”。
   * 不强制设定每步词数，而是鼓励输出更短、更精炼的思维链。

3. **Token-Budget Prompting**

   * 在 prompt 中给定 **token 预算**（如“请在 30 token 内完成推理”）。
   * 模型需在预算内完成 CoT，强制长度约束。

4. **Instruction-based Length Control**

   * 明确告诉模型：“只写关键步骤，避免冗余解释”。
   * 有时结合 few-shot 示例，展示短链路答案作为模仿范例。

---

# 特点

* **训练无关**：只需修改提示，部署方便。
* **透明性强**：用户能清楚看到 prompt 如何引导输出。
* **可组合**：可与 RL 或自一致性投票结合，进一步降成本。

---

# 与其他类别的对比

* **Prompt-guided**：从输入端约束输出（最轻量）。
* **Model-guided**：修改模型架构（如 early exit）。
* **Output-guided**：在解码阶段动态筛选、截断或压缩。

---

# 局限

* **依赖模型对指令的服从度**：有些模型可能仍生成冗长推理。
* **压缩过度风险**：若 prompt 过严，可能损失关键信息。
* **任务依赖性**：不同任务需要不同的 prompt 模板调优。

---

要不要我帮你整理一份 **Prompt 模板集合**（CoD、Token-Budget、简洁CoT），直接给你可用的英文指令，可以放进推理任务里实验？
